{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a506f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b55551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      "Processing: NPCK-2021-CATALOGUE-17.pdf\n",
      "  ✓ Loaded 94 pages\n",
      "\n",
      "Total documents loaded: 94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data/pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7f5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2f0c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 94 documents into 143 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: 2\n",
      "POTATO VARIETY CATALOGUE 2021...\n",
      "Metadata: {'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Windows)', 'creationdate': '2021-10-19T23:58:06+03:00', 'moddate': '2021-10-20T00:02:46+03:00', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\NPCK-2021-CATALOGUE-17.pdf', 'total_pages': 94, 'page': 1, 'page_label': '2', 'source_file': 'NPCK-2021-CATALOGUE-17.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "#chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49214cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stephen Mwangi\\Projects\\RAG Pipeline\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Emmbedding Dimension:, 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x2be9d3156a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### embedding And Vector Store DB\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SenteceTransformers\"\"\"\n",
    "\n",
    "    def __init__(self,model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"Initialize the EmbeddingManager with a specified model. \n",
    "        Args:\n",
    "            model_name Huggingface Model name for sentece Embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model.\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Emmbedding Dimension:, {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for a list of texts.\n",
    "        Args:\n",
    "            texts List of texts to generate embeddings for\n",
    "        Returns:\n",
    "            np.ndarray Array of embeddings with shape (len(texts), embedding_dimension)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded. Call _load_model() first.\")\n",
    "        \n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated {len(embeddings)} embeddings of shape {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "    def get_sentence_embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the dimension of the sentence embeddings.\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded. Call _load_model() first.\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721db505",
   "metadata": {},
   "source": [
    "\n",
    "### VECTOR STORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b3e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB client with persist directory: ../data/vector_store\n",
      "Vector store collection 'pdf_documents' initialized successfully.\n",
      "Existing collections: 143\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embedding in a ChromaDB vector store.\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"Initialize the VectorStore .\n",
    "        Args:\n",
    "            Collection name: Name of the vector database:\n",
    "            persist_directory: Directory to persist the vector database\n",
    "        \"\"\"\n",
    "        self.collection_name =collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize the ChromaDB client and collection.\"\"\"\n",
    "        try:\n",
    "            print(f\"Initializing ChromaDB client with persist directory: {self.persist_directory}\")\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            ## Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata= {\"description\": \"Collection of PDF document embeddings for RAG\"}\n",
    "                )\n",
    "            print(f\"Vector store collection '{self.collection_name}' initialized successfully.\")\n",
    "            print(f\"Existing collections: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self, documents: List[Any],embeddings:np.ndarray) -> List[str]:\n",
    "        \"\"\"Add documents to the ChromaDB collection after generating embeddings.\n",
    "\n",
    "        Args:\n",
    "            documents List of Document objects to add\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "            \n",
    "        \"\"\"\n",
    "        if len(documents) != len (embeddings):\n",
    "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
    "        \n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_lists = []\n",
    "\n",
    "        for i, (doc,embedding) in enumerate(zip(documents,embeddings)):\n",
    "            #Generate a unique ID for each document\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            ## Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length']  = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_lists.append(embedding.tolist())\n",
    "            \n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_lists,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store.\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding document {doc_id} to collection: {e}\")\n",
    "            raise\n",
    "            \n",
    "            \n",
    "vector_store = VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d06feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 143 embeddings of shape (143, 384)\n",
      "Successfully added 143 documents to vector store.\n",
      "Total documents in collection: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings and add to vector store\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## Add to vector store\n",
    "vector_store.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68548b1c",
   "metadata": {},
   "source": [
    "## Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b434292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"Initialize the RAGRetriever with a vector store and embedding manager.\n",
    "        Args:\n",
    "            vector_store Instance of the VectorStore class\n",
    "            embedding_manager Instance of the EmbeddingManager class for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "        \n",
    "        \n",
    "    def retrieve(self, query: str, top_k: int = 5,score_threshhold:float = 0.0) -> List[Dict[str, Any]]:\n",
    "            \"\"\"Retrieve top_k relevant documents for a given query.\n",
    "            Args:\n",
    "                query The user query string\n",
    "                top_k Number of top relevant documents to retrieve\n",
    "            Returns:\n",
    "                List of dictionaries containing retrieved documents with metadata\n",
    "            \"\"\"\n",
    "            print(f\"Retrieving top {top_k} documents for query: '{query}'\")\n",
    "            print(f\"Score Threshold: {score_threshhold}\")\n",
    "            \n",
    "            # Generate embedding for the query\n",
    "            query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "            \n",
    "            # Perform similarity search in the vector store\n",
    "            try:\n",
    "                results = self.vector_store.collection.query(\n",
    "                    query_embeddings=[query_embedding.tolist()],\n",
    "                    n_results=top_k,\n",
    "                    include=['metadatas', 'documents', 'distances']\n",
    "                )\n",
    "                \n",
    "                #Process results\n",
    "                retrieved_docs = []\n",
    "                if results['documents'] and results['documents'][0]:\n",
    "                    documents = results['documents'][0]\n",
    "                    metadatas = results['metadatas'][0]\n",
    "                    distances = results['distances'][0]\n",
    "                    ids = results['ids'][0]\n",
    "                    \n",
    "                    for i, (doc_id,document, metadata, distance) in enumerate(zip(ids,documents, metadatas, distances)):\n",
    "                        #similarity_score = 1 - distance  # Convert distance to similarity score\n",
    "                        if (1 - distance) >= score_threshhold:  # Convert distance to similarity score\n",
    "                            retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': 1 - distance,  # Convert distance to similarity score\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1})\n",
    "                    print(f\"Retrieved {len(retrieved_docs)} documents (after applying score threshold)\")  \n",
    "                else:\n",
    "                    print(\"No documents retrieved.\")\n",
    "                \n",
    "                return retrieved_docs     \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error during retrieval: {e}\")\n",
    "                return [] \n",
    "\n",
    "\n",
    "rag_retriever = RAGRetriever(vector_store, embedding_manager)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be76bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 3 documents for query: 'What is the National Potato Council of Kenya (NPCK)?'\n",
      "Score Threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 embeddings of shape (1, 384)\n",
      "Retrieved 3 documents (after applying score threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_2af49bfc_18',\n",
       "  'content': '9\\nPOTATO VARIETY CATALOGUE 2021\\nNATIONAL POTATO COUNCIL OF KENYA\\nThe National Potato Council of Kenya (NPCK) is a Public Private Partnership (PPP) and \\na multi-stakeholder organization whose responsibility is to help plan, organize, and \\nco-ordinate potato value chain activities and develop the subsector into a robust, \\ncompetitive, and self-regulating industry. The Potato Council organizational structure \\nenables it to draw synergies from a wide membership, representing all stakeholders \\nand actors in the potato industry.\\nNPCK VISION STATEMENT\\nPotato industry is a leading contributor to increased incomes, food security, and \\nimproved welfare in Kenya\\nNPCK MISSION STATEMENT\\nIt is NPCK’s mission to help coordinate and regulate Kenya’s potato industry, and help \\nimprove the industry’s profitability and the livelihoods of its various stakeholders.\\nNPCK OBJECTIVES\\nThe NPCK Strategic Plan is anchored on six objectives:',\n",
       "  'metadata': {'source': '..\\\\data\\\\pdf\\\\NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'content_length': 927,\n",
       "   'file_type': 'pdf',\n",
       "   'page': 8,\n",
       "   'creationdate': '2021-10-19T23:58:06+03:00',\n",
       "   'total_pages': 94,\n",
       "   'doc_index': 18,\n",
       "   'page_label': '9',\n",
       "   'source_file': 'NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'moddate': '2021-10-20T00:02:46+03:00',\n",
       "   'creator': 'Adobe InDesign CC 13.0 (Windows)',\n",
       "   'producer': 'Adobe PDF Library 15.0',\n",
       "   'trapped': '/False'},\n",
       "  'similarity_score': 0.5058606266975403,\n",
       "  'distance': 0.4941393733024597,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_e729d0bb_15',\n",
       "  'content': 'Cooperation (GIZ), Kenya-Netherlands Seed Potato Development Project, \\nKenya Agricultural and Livestock Research Organization (KALRO-Tigoni), Kenya \\nPlant Health Inspectorate Service (KEPHIS), International Potato Center (CIP), \\nInternational Fertilizer Development Center (IFDC), Syngenta Foundation for \\nSustainable Agriculture, National Research Fund (NRF) and SNV\\nWachira Kaguongo\\nChief Executive Officer,\\nNational Potato Council of Kenya\\nFOREWORD',\n",
       "  'metadata': {'creationdate': '2021-10-19T23:58:06+03:00',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'Adobe PDF Library 15.0',\n",
       "   'content_length': 451,\n",
       "   'source_file': 'NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'doc_index': 15,\n",
       "   'total_pages': 94,\n",
       "   'source': '..\\\\data\\\\pdf\\\\NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'trapped': '/False',\n",
       "   'creator': 'Adobe InDesign CC 13.0 (Windows)',\n",
       "   'page': 5,\n",
       "   'moddate': '2021-10-20T00:02:46+03:00',\n",
       "   'page_label': '6'},\n",
       "  'similarity_score': 0.3779944181442261,\n",
       "  'distance': 0.6220055818557739,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_ecbc9018_16',\n",
       "  'content': '7\\nPOTATO VARIETY CATALOGUE 2021\\nRepublic of Kenya\\nMinistry of Agriculture,\\nLivestock and Fisheries\\nKEPHIS\\nKENYA PLANT HEALTH\\nINSPECTORATE SERVICE\\nNATIONAL\\nRESEARCH\\nFUND\\nNRF\\nKENYA\\nfoundation\\nfor sustainable\\nagriculture\\nImplemented by\\nKALRO\\nKenya Agricultural & Livestock\\nResearch Organization\\nKEY PARTNERS',\n",
       "  'metadata': {'creationdate': '2021-10-19T23:58:06+03:00',\n",
       "   'creator': 'Adobe InDesign CC 13.0 (Windows)',\n",
       "   'content_length': 304,\n",
       "   'doc_index': 16,\n",
       "   'moddate': '2021-10-20T00:02:46+03:00',\n",
       "   'producer': 'Adobe PDF Library 15.0',\n",
       "   'page': 6,\n",
       "   'total_pages': 94,\n",
       "   'page_label': '7',\n",
       "   'source': '..\\\\data\\\\pdf\\\\NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'source_file': 'NPCK-2021-CATALOGUE-17.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': '/False'},\n",
       "  'similarity_score': 0.3270254135131836,\n",
       "  'distance': 0.6729745864868164,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is the National Potato Council of Kenya (NPCK)?\",top_k=3,score_threshhold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f25b1",
   "metadata": {},
   "source": [
    "## Integration Vectordb Context pipeline with LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19f908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]  \n",
    "\n",
    "### initialize the Grow LLM (set your GROQ_API_KEY in .env file)\n",
    "llm = ChatGroq(api_key=groq_api_key,model=\"gemma2-9b-it\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "## 2. Define a simple RAG function to combine retrieval and generation\n",
    "\n",
    "def rag_simple(query,rag_retriever,llm,top_k=3):\n",
    "    \"\"\"Simple RAG function to retrieve documents and generate an answer using LLM\"\"\"\n",
    "    # Step 1: Retrieve relevant documents\n",
    "    retrieved_docs = rag_retriever.retrieve(query, top_k=top_k)\n",
    "    \n",
    "    # Step 2: Combine retrieved documents into a context string\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in retrieved_docs]) if retrieved_docs else \"\"\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return \"No relevant documents found.\"\n",
    "    \n",
    "    \n",
    "    # Step 3: Create a prompt for the LLM\n",
    "    prompt = f\"Use the following context to answer the question concisely:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    #print(f\"\\nGenerated Prompt for LLM:\\n{prompt[:500]}...\\n\")  # Print first 500 characters of the prompt\n",
    "    \n",
    "    # Step 4: Generate an answer using the LLM\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285a9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 3 documents for query: 'What is the National Potato Council of Kenya (NPCK)?'\n",
      "Score Threshold: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 153.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 embeddings of shape (1, 384)\n",
      "Retrieved 3 documents (after applying score threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      "The National Potato Council of Kenya (NPCK) is a Public Private Partnership (PPP) that coordinates and regulates Kenya's potato industry to improve profitability and the livelihoods of its stakeholders.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"What is the National Potato Council of Kenya (NPCK)?\",rag_retriever,llm,top_k=3)\n",
    "print(f\"\\nGenerated Answer:\\n{answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe0224",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d0565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_advanced(query,rag_retriever,llm,top_k=3,min_score=0.2,return_context=False):\n",
    "    \"\"\"Advanced RAG function to retrieve documents and generate an answer using LLM with source attribution, confidence score, and optional full context\"\"\"\n",
    "    \n",
    "    # Step 1: Retrieve relevant documents\n",
    "    retrieved_docs = rag_retriever.retrieve(query, top_k=top_k,score_threshhold=min_score)\n",
    "    if not retrieved_docs:\n",
    "        return {'answer':\"No relevant documents found.\",'sources':[], 'confidence':0.0, 'context':\"\"}\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in retrieved_docs])\n",
    "    # Step 2: Combine retrieved documents into a context string with source attribution\n",
    "    \n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file',doc['metadata'].get('source','unknown source')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:120] + \"...\" # First 100 characters as preview\n",
    "    } for doc in retrieved_docs]\n",
    "    \n",
    "    confidence = max(doc['similarity_score'] for doc in retrieved_docs) \n",
    "    \n",
    "        \n",
    "    # Step 3: Create a prompt for the LLM\n",
    "    prompt = f\"Use the following context to answer the question concisely and cite sources:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\nAnswer (with sources):\"\n",
    "    \n",
    "    #print(f\"\\nGenerated Prompt for LLM:\\n{prompt[:500]}...\\n\")  # Print first 500 characters of the prompt\n",
    "    \n",
    "    # Step 4: Generate an answer using the LLM\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {'answer': response.content, 'sources': sources, 'confidence': confidence}\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26eccf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 3 documents for query: 'What is the National Potato Council of Kenya (NPCK)?'\n",
      "Score Threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 158.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 embeddings of shape (1, 384)\n",
      "Retrieved 3 documents (after applying score threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The National Potato Council of Kenya (NPCK) is a Public Private Partnership (PPP) and multi-stakeholder organization responsible for planning, organizing, and coordinating potato value chain activities in Kenya. Its goal is to develop a robust, competitive, and self-regulating potato industry.  (Source: NPCK Potato Variety Catalogue 2021, Foreword) \n",
      "\n",
      "\n",
      "\n",
      "Sources:\n",
      "Confidence: 0.5058606266975403\n",
      "Context Preview: 9\n",
      "POTATO VARIETY CATALOGUE 2021\n",
      "NATIONAL POTATO COUNCIL OF KENYA\n",
      "The National Potato Council of Kenya (NPCK) is a Public Private Partnership (PPP) and \n",
      "a multi-stakeholder organization whose responsibility is to help plan, organize, and \n",
      "co-ordinate potato value chain activities and develop the subs\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is the National Potato Council of Kenya (NPCK)?\",rag_retriever,llm,top_k=3,min_score=0.1,return_context=True)\n",
    "\n",
    "print(\"Answer:\",result['answer'])\n",
    "print(\"Sources:\"), result['sources']\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73260dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Pipeline (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
